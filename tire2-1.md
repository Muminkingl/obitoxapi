# ðŸ”¥ TIER 2 Implementation Plan - The Advanced Features

**Congratulations on completing TIER 1!** ðŸŽ‰ Now let's build features that will make ObitoX **absolutely unstoppable**!

---

# ðŸ“‹ TIER 2 Overview

| Feature | Pain Level | Impact | Complexity | Time |
|---------|-----------|--------|------------|------|
| **Resumable Multipart Uploads** | ðŸ”´ðŸ”´ Critical | ðŸš€ðŸš€ðŸš€ Huge | ðŸŸ¡ Medium | 4-6 hours |
| **Upload Completion Webhooks** | ðŸ”´ High | ðŸš€ðŸš€ High | ðŸŸ¢ Easy | 2-3 hours |
| **Batch Presigned URLs** | ðŸŸ¡ Medium | ðŸš€ Medium | ðŸŸ¢ Easy | 1-2 hours |

**Total Time:** 7-11 hours to complete TIER 2

---

# ðŸŽ¯ Priority Order (Recommended)

1. **Batch Presigned URLs** (Easy win, 1-2 hours) âœ… Start here!
2. **Upload Completion Webhooks** (High impact, 2-3 hours)
3. **Resumable Multipart Uploads** (Most complex, 4-6 hours)

---

# ðŸ“¦ FEATURE #1: Batch Presigned URLs

## ðŸ”¥ The Pain Point

```javascript
// âŒ CURRENT: Upload 20 files = 20 API calls (SLOW!)
for (const file of files) {
    const signedUrl = await fetch('/api/v1/upload/s3/signed-url', {
        method: 'POST',
        body: JSON.stringify({
            filename: file.name,
            contentType: file.type
        })
    });
    // 20 sequential network requests = 2-5 seconds! ðŸ˜¡
}

// âœ… NEW: Upload 20 files = 1 API call (FAST!)
const signedUrls = await fetch('/api/v1/upload/s3/batch-signed-urls', {
    method: 'POST',
    body: JSON.stringify({
        files: files.map(f => ({
            filename: f.name,
            contentType: f.type,
            fileSize: f.size
        }))
    })
});
// 1 network request = 200ms! ðŸš€
```

---

## ðŸ“ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    BATCH SIGNED URLS FLOW                        â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                 â”‚
â”‚  Client has 20 files to upload                                  â”‚
â”‚         â”‚                                                        â”‚
â”‚         â–¼                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚ POST /batch-signed-urls              â”‚                      â”‚
â”‚  â”‚ Body: {                               â”‚                      â”‚
â”‚  â”‚   files: [                            â”‚                      â”‚
â”‚  â”‚     { filename, contentType, size },  â”‚                      â”‚
â”‚  â”‚     { filename, contentType, size },  â”‚                      â”‚
â”‚  â”‚     ... (20 files)                    â”‚                      â”‚
â”‚  â”‚   ]                                   â”‚                      â”‚
â”‚  â”‚ }                                     â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚         â”‚                                                        â”‚
â”‚         â–¼                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚ Backend processes in parallel:       â”‚                      â”‚
â”‚  â”‚ â€¢ Validate all files                  â”‚                      â”‚
â”‚  â”‚ â€¢ Generate 20 signed URLs             â”‚                      â”‚
â”‚  â”‚ â€¢ Return in same order                â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚         â”‚                                                        â”‚
â”‚         â–¼                                                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                      â”‚
â”‚  â”‚ Response: {                           â”‚                      â”‚
â”‚  â”‚   signedUrls: [                       â”‚                      â”‚
â”‚  â”‚     { url, filename, key, ... },      â”‚                      â”‚
â”‚  â”‚     { url, filename, key, ... },      â”‚                      â”‚
â”‚  â”‚     ... (20 URLs)                     â”‚                      â”‚
â”‚  â”‚   ]                                   â”‚                      â”‚
â”‚  â”‚ }                                     â”‚                      â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                      â”‚
â”‚         â”‚                                                        â”‚
â”‚         â–¼                                                        â”‚
â”‚  Client uploads 20 files in parallel                            â”‚
â”‚  (5-10 concurrent uploads)                                      â”‚
â”‚                                                                 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ› ï¸ Implementation

### Step 1: Create Batch Signed URL Controller

**File:** `controllers/providers/s3/s3.batch-signed-url.js`

```javascript
import { generateS3SignedUrlInternal } from './s3.signed-url.js';
import { validateFileMetadata } from '../../../utils/file-validator.js';

/**
 * POST /api/v1/upload/s3/batch-signed-urls
 * Generate multiple signed URLs in one request
 */
export async function generateBatchS3SignedUrls(req, res) {
    try {
        const {
            files,           // Array of { filename, contentType, fileSize, ... }
            s3AccessKey,
            s3SecretKey,
            s3Bucket,
            s3Region,
            validation,      // Optional: Apply same validation to all files
            concurrency = 10 // Max concurrent URL generation
        } = req.body;

        // Validate input
        if (!files || !Array.isArray(files) || files.length === 0) {
            return res.status(400).json({
                success: false,
                error: 'INVALID_INPUT',
                message: 'files array is required and must not be empty'
            });
        }

        // Limit batch size
        if (files.length > 100) {
            return res.status(400).json({
                success: false,
                error: 'BATCH_TOO_LARGE',
                message: 'Maximum 100 files per batch',
                maxFiles: 100,
                providedFiles: files.length
            });
        }

        const startTime = Date.now();
        const results = [];

        // âœ… Process files in parallel (with concurrency limit)
        const processFile = async (fileMetadata, index) => {
            try {
                // 1. Validate file (if validation rules provided)
                if (validation) {
                    const validationResult = validateFileMetadata({
                        ...fileMetadata,
                        validation
                    });

                    if (!validationResult.valid) {
                        return {
                            success: false,
                            filename: fileMetadata.filename,
                            index,
                            error: 'VALIDATION_FAILED',
                            validationErrors: validationResult.errors
                        };
                    }

                    // Use sanitized filename if available
                    if (validationResult.sanitizedFilename) {
                        fileMetadata.filename = validationResult.sanitizedFilename;
                    }
                }

                // 2. Generate signed URL
                const signedUrlData = await generateS3SignedUrlInternal({
                    filename: fileMetadata.filename,
                    contentType: fileMetadata.contentType,
                    fileSize: fileMetadata.fileSize,
                    s3AccessKey,
                    s3SecretKey,
                    s3Bucket,
                    s3Region,
                    ...fileMetadata // Pass through any extra options
                });

                return {
                    success: true,
                    index,
                    ...signedUrlData
                };

            } catch (error) {
                console.error(`[Batch] Error generating URL for file ${index}:`, error);
                return {
                    success: false,
                    filename: fileMetadata.filename,
                    index,
                    error: error.message
                };
            }
        };

        // Process files with concurrency limit
        for (let i = 0; i < files.length; i += concurrency) {
            const batch = files.slice(i, i + concurrency);
            const batchResults = await Promise.all(
                batch.map((file, batchIndex) => processFile(file, i + batchIndex))
            );
            results.push(...batchResults);
        }

        // Separate successful and failed URLs
        const successful = results.filter(r => r.success);
        const failed = results.filter(r => !r.success);

        const totalTime = Date.now() - startTime;

        return res.json({
            success: true,
            total: files.length,
            successful: successful.length,
            failed: failed.length,
            signedUrls: successful,
            errors: failed.length > 0 ? failed : undefined,
            processingTime: totalTime,
            avgTimePerFile: Math.round(totalTime / files.length)
        });

    } catch (error) {
        console.error('[Batch] Error:', error);
        return res.status(500).json({
            success: false,
            error: 'BATCH_GENERATION_FAILED',
            message: error.message
        });
    }
}
```

---

### Step 2: Extract Signed URL Generation Logic

**File:** `controllers/providers/s3/s3.signed-url.js`

```javascript
/**
 * Internal function to generate signed URL (reusable)
 */
export async function generateS3SignedUrlInternal(options) {
    const {
        filename,
        contentType,
        fileSize,
        s3AccessKey,
        s3SecretKey,
        s3Bucket,
        s3Region,
        s3StorageClass,
        s3EncryptionType,
        expiresIn = 3600
    } = options;

    const s3 = getS3Client(s3AccessKey, s3SecretKey, s3Region);

    const key = `${Date.now()}_${filename}`;
    
    const params = {
        Bucket: s3Bucket,
        Key: key,
        Expires: expiresIn,
        ContentType: contentType,
        ...(s3StorageClass && { StorageClass: s3StorageClass }),
        ...(s3EncryptionType && { ServerSideEncryption: s3EncryptionType })
    };

    const signedUrl = await s3.getSignedUrlPromise('putObject', params);

    return {
        signedUrl,
        key,
        bucket: s3Bucket,
        region: s3Region,
        filename,
        expiresIn,
        expiresAt: new Date(Date.now() + expiresIn * 1000).toISOString()
    };
}

/**
 * Existing single signed URL endpoint (now uses internal function)
 */
export async function generateS3SignedUrl(req, res) {
    try {
        const signedUrlData = await generateS3SignedUrlInternal(req.body);
        
        return res.json({
            success: true,
            ...signedUrlData
        });
    } catch (error) {
        // Handle error...
    }
}
```

---

### Step 3: Add Batch Route

**File:** `routes/upload.routes.js`

```javascript
import { generateBatchS3SignedUrls } from '../controllers/providers/s3/s3.batch-signed-url.js';

// Batch signed URLs
router.post('/s3/batch-signed-urls', authenticate, generateBatchS3SignedUrls);
```

---

### Step 4: Add SDK Method

**File:** `sdk/providers/s3.provider.js`

```javascript
export class S3Provider {
    // ... existing methods

    /**
     * âœ… NEW: Upload multiple files at once
     */
    async uploadFiles(files, options) {
        // 1. Get batch signed URLs
        const response = await this.makeRequest('/upload/s3/batch-signed-urls', {
            method: 'POST',
            body: {
                files: files.map(file => ({
                    filename: file.name,
                    contentType: file.type,
                    fileSize: file.size
                })),
                ...options
            }
        });

        if (!response.success) {
            throw new Error(`Batch signed URL generation failed: ${response.error}`);
        }

        // 2. Upload files in parallel (with concurrency limit)
        const concurrency = options.concurrency || 5;
        const uploadResults = [];

        for (let i = 0; i < files.length; i += concurrency) {
            const batch = files.slice(i, i + concurrency);
            const batchUrls = response.signedUrls.slice(i, i + concurrency);

            const batchResults = await Promise.all(
                batch.map((file, index) => 
                    this.uploadToSignedUrl(file, batchUrls[index].signedUrl)
                        .then(url => ({
                            success: true,
                            file: file.name,
                            url: batchUrls[index].signedUrl.split('?')[0],
                            key: batchUrls[index].key
                        }))
                        .catch(error => ({
                            success: false,
                            file: file.name,
                            error: error.message
                        }))
                )
            );

            uploadResults.push(...batchResults);
        }

        const successful = uploadResults.filter(r => r.success);
        const failed = uploadResults.filter(r => !r.success);

        return {
            total: files.length,
            successful: successful.length,
            failed: failed.length,
            urls: successful.map(r => r.url),
            results: uploadResults
        };
    }

    /**
     * Upload single file to signed URL
     */
    async uploadToSignedUrl(file, signedUrl) {
        const response = await fetch(signedUrl, {
            method: 'PUT',
            body: file,
            headers: {
                'Content-Type': file.type
            }
        });

        if (!response.ok) {
            throw new Error(`Upload failed: ${response.status}`);
        }

        return signedUrl.split('?')[0];
    }
}
```

---

## ðŸ“Š Usage Examples

### Example 1: Basic Batch Upload

```javascript
const client = new ObitoX({ apiKey: '...', apiSecret: '...' });

const files = Array.from(fileInput.files); // 20 files

// âœ… Upload all files in one SDK call!
const result = await client.uploadFiles(files, {
    provider: 'S3',
    s3AccessKey: '...',
    s3SecretKey: '...',
    s3Bucket: 'my-bucket',
    s3Region: 'us-east-1',
    concurrency: 5 // Upload 5 files at a time
});

console.log(`âœ… Uploaded: ${result.successful}/${result.total}`);
console.log('URLs:', result.urls);

if (result.failed > 0) {
    console.error('Failed uploads:', result.results.filter(r => !r.success));
}
```

### Example 2: With Validation

```javascript
const result = await client.uploadFiles(files, {
    provider: 'S3',
    s3Bucket: 'my-bucket',
    s3Region: 'us-east-1',
    
    // âœ… Validate all files
    validation: {
        maxSizeMB: 10,
        allowedTypes: ['image/jpeg', 'image/png']
    }
});

// Files that failed validation won't get signed URLs
```

### Example 3: With Progress Tracking

```javascript
const files = Array.from(fileInput.files);
let uploadedCount = 0;

const result = await client.uploadFiles(files, {
    provider: 'S3',
    s3Bucket: 'my-bucket',
    
    // Custom upload handler for progress
    onFileUploaded: (file, url) => {
        uploadedCount++;
        updateProgressBar(uploadedCount / files.length);
        console.log(`âœ… ${file.name} uploaded`);
    }
});
```

---

## âœ… Feature #1 Complete!

**What you just built:**
- âœ… Batch signed URL generation (1 API call for 100 files)
- âœ… Parallel processing with concurrency control
- âœ… Validation for all files in batch
- âœ… Error handling (partial success/failure)
- âœ… SDK method `uploadFiles()`
- âœ… 10-20x faster than sequential uploads

**Performance:**
- **Before:** 20 files = 20 API calls = 2-5 seconds
- **After:** 20 files = 1 API call = 200ms
- **Speed improvement:** 10-25x faster! ðŸš€

---
